{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Use_MobelenetV2.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "ZH0_G1WSL4F9",
        "7yKl-8RtazlM"
      ],
      "authorship_tag": "ABX9TyPoUJgpqR2HZXNS8IYbuT8I",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/saotomryo/Image_Identification/blob/master/Use_MobelenetV2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YIv4_a5ONPst"
      },
      "source": [
        "# はじめに\n",
        "\n",
        "まず、「ctrl F９」またはツールメニューの「ランタイム」から「全てのセル」の実行を選択してください。\n",
        "\n",
        "\n",
        "# 学習用ファイルのアップロード\n",
        "\n",
        "「ファイルの選択」ボタンをクリックして、以下の形式で画像をまとめたファイルをZIP形式で圧縮したファイルをドラック&ドロップでアップロードしてください。\n",
        "\n",
        "アップロード後、アップロードしたファイル名を下記のフォームに記入してください。\n",
        "\n",
        "\n",
        "全体のフォルダ\n",
        "\n",
        "　- ラベル付けを行うフォルダ（フォルダ名を「正解ラベルの名前」（日本語不可）としてください。）\n",
        "\n",
        "　　　　　- 各画像ファイル\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0MRGy99KYeRS"
      },
      "source": [
        "from google.colab import files\n",
        "file_name = files.upload()\n",
        "file_name = list(file_name.keys())[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZH0_G1WSL4F9"
      },
      "source": [
        "# 利用するパッケージのインポート\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UgcToFwTMHO4"
      },
      "source": [
        "!pip install git+https://github.com/ildoonet/pytorch-gradual-warmup-lr.git\n",
        "\n",
        "!pip install torch==1.10.0\n",
        "!pip install torchvision==0.11.1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6YDyxM4btkDq"
      },
      "source": [
        "from PIL import Image\n",
        "import os\n",
        "from glob import glob\n",
        "import re\n",
        "\n",
        "import cloudpickle\n",
        "import pandas as pd\n",
        "import torch\n",
        "from torchvision import transforms\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from tqdm import tqdm\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from sklearn.metrics import f1_score,accuracy_score\n",
        "from statistics import mean\n",
        "\n",
        "import warmup_scheduler\n",
        "from torchvision.models import mobilenetv2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rDliVHEp9voc"
      },
      "source": [
        "# zipファイルをアップロードした時の対応\n",
        "\n",
        "import zipfile\n",
        "with zipfile.ZipFile(file_name) as existing_zip:\n",
        "    existing_zip.extractall()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jFprP2ygSX4y"
      },
      "source": [
        "file_name = file_name[:-4]\n",
        "%cd $file_name\n",
        "\n",
        "folders = os.listdir(\"./\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oH-Gsx_ivEfv"
      },
      "source": [
        "from glob import glob\n",
        "import pandas as pd\n",
        "\n",
        "tmp = []\n",
        "\n",
        "for folder in folders:\n",
        "    if folder[0] != '.':\n",
        "        filiename_list = [p for p in glob('./' + folder + '/*.*') if re.search('/*\\.(jpg|jpeg|JPG|GPEG)', str(p))]\n",
        "        print(filiename_list)\n",
        "        for filename in filiename_list:\n",
        "            category = folder\n",
        "            tmp.append([filename,category])\n",
        "\n",
        "# １レコードがファイルパスとカテゴリー（正解ラベル）になるようにDataFrameにまとめる\n",
        "train_df = pd.DataFrame(tmp, columns=['path', 'category'])\n",
        "\n",
        "# カテゴリーをID（数値）に変換した列を追加する\n",
        "categories = train_df['category'].sort_values(ascending=True).unique().tolist()\n",
        "train_df['category_id'] = train_df['category'].map(lambda x: categories.index(x))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7yKl-8RtazlM"
      },
      "source": [
        "# 学習の準備"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HydzA6CBt2S3"
      },
      "source": [
        "# データの前処理及びデータ水増し\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.RandomRotation(degrees=(-10,10)), # 5度の範囲で画像をランダムに回転\n",
        "    transforms.RandomHorizontalFlip(), # 水扁反転\n",
        "    transforms.RandomVerticalFlip(), # 垂直反転\n",
        "    transforms.RandomResizedCrop(size=(224,224),scale=(0.9,0.9),ratio=(1.0,1.0)), # アスペクト比を保って、0.9倍のサイズでランダムに画像を224x224に切り出し\n",
        "    transforms.ToTensor(),\n",
        "    transforms.RandomErasing(p=0.2, scale=(0.02, 0.03)),# ランダムに画像の一部を削除\n",
        "    transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)), # ImageNetに合わせて画像の標準化\n",
        "])\n",
        "val_transform = transforms.Compose([ # 検証データ用の画像の前処理\n",
        "    #transforms.RandomResizedCrop(size=(224,224),scale=(1.0,1.0),ratio=(1.0,1.0)), # アスペクト比を保って画像をリサイズ\n",
        "    transforms.Resize((224,224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wah64NtdTzUS"
      },
      "source": [
        "EPOCHS = 30  # 学習を回す回数\n",
        "BATCH_SIZE = 32 # 一回に並列で演算する個数\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5kOdKIWvw7rN"
      },
      "source": [
        "class TrainData(Dataset):\n",
        "    def __init__(self, df, phase):\n",
        "        self.images = []\n",
        "        self.categories = []\n",
        "\n",
        "        for row in tqdm(df.itertuples(), total=df.shape[0]):\n",
        "            path = row.path\n",
        "            # 正解ラベルなしのテストデータの場合は、category_idを0とする\n",
        "            if phase != 'test':\n",
        "                category = row.category_id\n",
        "            else:\n",
        "                category = 0\n",
        "            image = Image.open(path)\n",
        "\n",
        "            # 学習用データの定義\n",
        "            if phase == 'train':\n",
        "\n",
        "                try:\n",
        "                    # 学習用の処理を行なったデータ\n",
        "                    feature_ids = torch.reshape(transform(image),(-1, 3, 224, 224)).squeeze(0)\n",
        "                    self.images.append(feature_ids)\n",
        "                    self.categories.append(category)\n",
        "                    # 学習用の処理を行なっていないデータ\n",
        "                    feature_ids = torch.reshape(val_transform(image),(-1, 3, 224, 224)).squeeze(0)\n",
        "                    self.images.append(feature_ids)\n",
        "                    self.categories.append(category)\n",
        "                except:\n",
        "                    print('error')\n",
        "                    pass\n",
        "            else:\n",
        "\n",
        "                try:\n",
        "                    # 学習用の処理を行なっていないデータ\n",
        "                    feature_ids = torch.reshape(val_transform(image),(-1, 3, 224, 224)).squeeze(0)\n",
        "                    self.images.append(feature_ids)\n",
        "                    self.categories.append(category)\n",
        "                except:\n",
        "                    print('error')\n",
        "                    pass\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.images)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.images[idx], self.categories[idx]\n",
        "\n",
        "\n",
        "# 学習と検証を8:2に分ける\n",
        "train_df2, val_df = train_test_split(train_df,train_size=0.8,random_state=2)\n",
        "print(train_df.shape, val_df.shape)\n",
        "\n",
        "#　データ読み込み\n",
        "train_data = TrainData(train_df2,'train')\n",
        "val_data = TrainData(val_df,'val')\n",
        "\n",
        "# DataLoaderを取得する\n",
        "train_loader = DataLoader(train_data, batch_size=BATCH_SIZE, shuffle=True)\n",
        "val_loader = DataLoader(val_data, batch_size=BATCH_SIZE, shuffle=False)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Na_xHjz1fXOF"
      },
      "source": [
        "# 事前学習済みモデルのインポート\n",
        "\n",
        "# モデル本体\n",
        "mob_model = mobilenetv2.mobilenet_v2(pretrained=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RarSbf2NyHNf"
      },
      "source": [
        "# モデルクラスの宣言\n",
        "\n",
        "class Mobilenetv2(nn.Module):\n",
        "    def __init__(self, pretrained_mob_model, class_num):\n",
        "        super(Mobilenetv2, self).__init__()\n",
        "        self.class_num = len(categories)\n",
        "        self.vit = pretrained_mob_model #学習ずみモデル\n",
        "        self.fc = nn.Linear(1000, class_num)\n",
        "        self.categories = categories\n",
        "\n",
        "    def get_class_num(self):\n",
        "        return self.class_num\n",
        "\n",
        "    def forward(self, input_ids):\n",
        "        states = self.vit(input_ids)\n",
        "        states = self.fc(states)\n",
        "        return states\n",
        "\n",
        "# 今回のデータのカテゴリ（フォルダ数）\n",
        "CLASS_NUM = len(categories)\n",
        "\n",
        "# 事前学習済モデルを引数で渡します。\n",
        "net = Mobilenetv2(mob_model, CLASS_NUM)\n",
        "\n",
        "# モデルのstate_dictに追加情報を渡す。\n",
        "#net.state_dict['categories'] = categories\n",
        "\n",
        "# GPUの設定\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "net.to(device)\n",
        "\n",
        "# モデルの初期値を保存する（xxxxに保存するパスを記載してください）\n",
        "model_path = '/content/default_model.pth'\n",
        "#torch.save(net.state_dict(),model_path)\n",
        "torch.save(net,model_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bw6a3F-LfX4Z"
      },
      "source": [
        "class LabelSmoothingCrossEntropyLoss(nn.Module):\n",
        "    def __init__(self, classes, smoothing=0.0, dim=-1):\n",
        "        super(LabelSmoothingCrossEntropyLoss, self).__init__()\n",
        "        self.confidence = 1.0 - smoothing\n",
        "        self.smoothing = smoothing\n",
        "        self.cls = classes\n",
        "        self.dim = dim\n",
        "\n",
        "    def forward(self, pred, target):\n",
        "        pred = pred.log_softmax(dim=self.dim)\n",
        "        with torch.no_grad():\n",
        "            true_dist = torch.zeros_like(pred)\n",
        "            true_dist.fill_(self.smoothing / (self.cls - 1))\n",
        "            true_dist.scatter_(1, target.data.unsqueeze(1), self.confidence)\n",
        "        return torch.mean(torch.sum(-true_dist * pred, dim=self.dim))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tKzeFyORz0KX"
      },
      "source": [
        "# まず全パラメータを勾配計算Falseにする\n",
        "for param in net.parameters():\n",
        "    param.requires_grad = False\n",
        "    #param.requires_grad = True\n",
        "\n",
        "# 最終層を勾配計算ありに変更\n",
        "for param in net.vit.features[18].parameters():\n",
        "    param.requires_grad = True\n",
        "\n",
        "# 最終層を勾配計算ありに変更\n",
        "for param in net.vit.classifier.parameters():\n",
        "    param.requires_grad = True\n",
        "\n",
        "# 追加したクラス分類用の全結合層を勾配計算ありに変更\n",
        "for param in net.fc.parameters():\n",
        "    param.requires_grad = True\n",
        "\n",
        "\n",
        "optimizer = torch.optim.SGD(net.parameters(), lr=0.1, momentum=0.9, nesterov=False)\n",
        "\n",
        "# 損失関数\n",
        "#criterion = nn.CrossEntropyLoss()\n",
        "criterion = LabelSmoothingCrossEntropyLoss(classes=4, smoothing=0.05)\n",
        "\n",
        "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=20)\n",
        "\n",
        "import warmup_scheduler\n",
        "scheduler_w = warmup_scheduler.GradualWarmupScheduler(optimizer, multiplier=1., total_epoch=5, after_scheduler=scheduler)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rHOurMfIz03H"
      },
      "source": [
        "from sklearn.metrics import f1_score,accuracy_score\n",
        "\n",
        "train_losses = []\n",
        "val_losses = []\n",
        "train_fscores = []\n",
        "val_fscores = []\n",
        "train_accuracies = []\n",
        "val_accuracies = []\n",
        "\n",
        "pre_fscore = 0\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "\n",
        "    # 学習\n",
        "    train_loss = 0.0\n",
        "    train_predict = []\n",
        "    train_answer = []\n",
        "    train_predict2 = []\n",
        "    train_answer2 = []\n",
        "    net.train()\n",
        "    for batch in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        input_ids = batch[0].to(device)\n",
        "        y = batch[1].to(device)\n",
        "        out = net(input_ids)\n",
        "        loss = criterion(out, y)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        train_predict += out.argmax(dim=1).cpu().detach().numpy().tolist()\n",
        "        train_answer += y.cpu().detach().numpy().tolist()\n",
        "        train_loss += loss.item()\n",
        "\n",
        "    # warmupの実装\n",
        "    scheduler_w.step()\n",
        "\n",
        "    # エポックごとの損失の合計とF1-scoreを計算する\n",
        "    train_losses.append(train_loss)\n",
        "    train_fscore = f1_score(train_answer, train_predict, average='macro')\n",
        "    train_fscores.append(train_fscore)\n",
        "    train_accuracy = accuracy_score(train_answer, train_predict)\n",
        "    train_accuracies.append(train_accuracy)\n",
        "\n",
        "    # 検証\n",
        "    val_loss = 0.0\n",
        "    val_predict = []\n",
        "    val_answer = []\n",
        "    net.eval()\n",
        "    for batch in val_loader:\n",
        "        with torch.no_grad():\n",
        "\n",
        "            input_ids = batch[0].to(device)\n",
        "            y = batch[1].to(device)\n",
        "            out = net(input_ids)\n",
        "            loss = criterion(out, y)\n",
        "\n",
        "            val_loss += loss.item()\n",
        "            _, y_pred = torch.max(out, 1)            \n",
        "            val_predict += out.argmax(dim=1).cpu().detach().numpy().tolist()\n",
        "            val_answer += y.cpu().detach().numpy().tolist()\n",
        "\n",
        "\n",
        "    # エポックごとの損失の合計とF1-scoreを計算する\n",
        "    val_losses.append(val_loss)\n",
        "    val_fscore = f1_score(val_answer, val_predict, average='macro')\n",
        "    val_fscores.append(val_fscore)\n",
        "    val_accuracy = accuracy_score(val_answer, val_predict)\n",
        "    val_accuracies.append(val_accuracy)\n",
        "\n",
        "    print('epoch', epoch,\n",
        "          '\\ttrain loss', round(train_loss, 4), '\\ttrain fscore', round(train_fscore, 4) ,'\\ttrain accuracy', round(train_accuracy,4),\n",
        "          '\\tval loss', round(val_loss, 4), '\\tval fscore', round(val_fscore, 4) ,'\\tval accuracy', round(val_accuracy,4),\n",
        "          )\n",
        "    \n",
        "    \n",
        "    if val_fscore > pre_fscore:\n",
        "        best_model = net\n",
        "        model_path = '/content/model' + str(round(val_fscore,2))[2:] + '.pth'\n",
        "        #torch.save(net.state_dict(),model_path)\n",
        "        torch.save(net.to('cpu'),model_path)\n",
        "        #with open(model_path, 'wb') as f:\n",
        "        #    cloudpickle.dump(net.to('cpu'), f)\n",
        "        net.to(device)\n",
        "        pre_fscore = val_fscore\n",
        "\n",
        "    net = best_model\n",
        "    \n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lnvO1KF3bF7q"
      },
      "source": [
        "# 学習結果の確認"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ic5MyOpXjMjh"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(15,5))\n",
        "\n",
        "plt.subplot(1,3,1)\n",
        "plt.plot(train_losses, '-o', label='train loss')\n",
        "plt.plot(val_losses, '-^', label='val loss')\n",
        "plt.title('loss')\n",
        "plt.legend()\n",
        "plt.grid()\n",
        "\n",
        "plt.subplot(1,3,2)\n",
        "plt.plot(train_fscores, '-o', label='train fscore')\n",
        "plt.plot(val_fscores, '-^', label='val fscore')\n",
        "plt.title('fscore')\n",
        "plt.legend()\n",
        "plt.grid()\n",
        "\n",
        "plt.subplot(1,3,3)\n",
        "plt.plot(train_accuracies, '-o', label='train accuracy')\n",
        "plt.plot(val_accuracies, '-^', label='val accuracy')\n",
        "plt.title('accuracy')\n",
        "plt.legend()\n",
        "plt.grid()\n",
        "\n",
        "print(f'このモデルの正解率は{round(np.array(val_accuracies).max(),4)}です\\n')\n",
        "plt.show()\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bfvi6NVe6Hw9"
      },
      "source": [
        "# 結果の確認\n",
        "\n",
        "今回は学習データの上位10個が正常に予測できていることを確認します。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GsDfwrAV5rxj",
        "outputId": "ab41a90d-fabb-4a83-c57e-b22a4db2b6db"
      },
      "source": [
        "\n",
        "# 最初のデータの出力を確認する\n",
        "test_data = TrainData(train_df,'test')\n",
        "\n",
        "# DataLoaderを取得する\n",
        "test_loader = DataLoader(test_data, batch_size=1, shuffle=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 113/113 [00:02<00:00, 40.40it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EpHAQJSa6DzL"
      },
      "source": [
        "配列の最も大きいものが予測値となります。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H-AZFLs253oM"
      },
      "source": [
        "preds = []\n",
        "for batch in test_loader:\n",
        "    input_ids = batch[0].to('cpu')\n",
        "    net = net.to('cpu')\n",
        "    out = net(input_ids)\n",
        "    pred = out.argmax(dim=1)\n",
        "    preds.append(pred.detach().numpy()[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Vu62iAB6P_D"
      },
      "source": [
        "category_idと予測値が同じになることを確認してください。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sGzE05Aa57Xg"
      },
      "source": [
        "train_df['pred'] = preds\n",
        "train_df['正解'] = [1 if train_df['category_id'][i] == train_df['pred'][i] else 0 for i in range(len(train_df))]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "teLwpDxp5-9S"
      },
      "source": [
        "train_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-h8y6piMp-yp"
      },
      "source": [
        "# 画像ラベルとラベルIDの関係の確認\n",
        "\n",
        "学習ずみモデルは「category_id」の数字の値を出力します。\n",
        "「category」が写真のフォルダ名になります。画像認識アプリはラベル名を出力しますが、カスタマイズアプリケーションを作る場合はラベルIDが必要になります。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SgnfTIjRsmCT"
      },
      "source": [
        "# 画像のラベルとラベルIDの関係を確認します。\n",
        "\n",
        "train_df[['category','category_id']].groupby('category').mean()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5HMJ_0Nkp58a"
      },
      "source": [
        "# 学習したモデルのダウンロード"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JwoUM6dZtFzs"
      },
      "source": [
        "from google.colab import files\n",
        "files.download(model_path)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2OY9sYa2qX9-"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}